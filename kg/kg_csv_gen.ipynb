{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfDWLnHP9g3z",
        "outputId": "6145105d-727b-4960-e3a2-d86ed2921ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.13 (from langchain-community)\n",
            "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.27 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.13 langchain-community-0.3.13 langchain-core-0.3.28 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.0 typing-inspect-0.9.0\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.27.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n",
            "Downloading neo4j-5.27.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neo4j\n",
            "Successfully installed neo4j-5.27.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv\n",
        "!pip install langchain-community\n",
        "!pip install neo4j\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cWsbQOUQ9xCd"
      },
      "outputs": [],
      "source": [
        "load_dotenv('/content/sample_data/.env', override=True)\n",
        "NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE')\n",
        "OPENAI_API_KEY = ''\n",
        "OPENAI_ENDPOINT = 'https://api.openai.com/v1/embeddings'#os.getenv('OPENAI_BASE_URL') + '/embeddings'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G6aT2L3w95WP"
      },
      "outputs": [],
      "source": [
        "kg = Neo4jGraph (\n",
        "    url= \"neo4j+s://221b4037.databases.neo4j.io\", username=\"neo4j\", password=\"\", database=\"neo4j\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkcvMdPlP4OP",
        "outputId": "6bc78057-088a-4a40-e1da-984ed224e430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.query(\"\"\"\n",
        "  CREATE VECTOR INDEX movie_tagline_embeddings IF NOT EXISTS\n",
        "  FOR (m:Movie) ON (m.taglineEmbedding)\n",
        "  OPTIONS { indexConfig: {\n",
        "    `vector.dimensions`: 1536,\n",
        "    `vector.similarity_function`: 'cosine'\n",
        "  }}\"\"\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuMncUfrUvPC",
        "outputId": "a12b9afc-3195-4a56-dae9-131e0a80006d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.query(\"\"\"\n",
        "    MATCH (movie:Movie) WHERE movie.tagline IS NOT NULL\n",
        "    WITH movie, genai.vector.encode(\n",
        "        movie.tagline,\n",
        "        \"OpenAI\",\n",
        "        {\n",
        "          token: $openAiApiKey,\n",
        "          endpoint: $openAiEndpoint\n",
        "        }) AS vector\n",
        "    CALL db.create.setNodeVectorProperty(movie, \"taglineEmbedding\", vector)\n",
        "    \"\"\",\n",
        "    params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zp6Wh5fSciU",
        "outputId": "c5dfb9a3-8684-4ac4-d8f2-736c49a5d9a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': 6,\n",
              "  'name': 'movie_tagline_embeddings',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'VECTOR',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Movie'],\n",
              "  'properties': ['taglineEmbedding'],\n",
              "  'indexProvider': 'vector-2.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': neo4j.time.DateTime(2024, 12, 22, 19, 17, 1, 967000000, tzinfo=<UTC>),\n",
              "  'readCount': 1}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.query(\"\"\"\n",
        "  SHOW VECTOR INDEXES\n",
        "  \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "57Opca0nX67n"
      },
      "outputs": [],
      "source": [
        "question = \"what movies are about sci-fi ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrJqNYYrTElp",
        "outputId": "ba6c4293-2fa4-4659-a206-c567a91dc14c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: title)} {position: line: 13, column: 18, offset: 341} for query: '\\n    WITH genai.vector.encode(\\n        $question,\\n        \"OpenAI\",\\n        {\\n          token: $openAiApiKey,\\n          endpoint: $openAiEndpoint }) AS question_embedding\\n    CALL db.index.vector.queryNodes(\\n        \\'movie_tagline_embeddings\\',\\n        $top_k,\\n        question_embedding\\n        ) YIELD node AS movie, score\\n    RETURN movie.title, movie.tagline, score\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: tagline)} {position: line: 13, column: 31, offset: 354} for query: '\\n    WITH genai.vector.encode(\\n        $question,\\n        \"OpenAI\",\\n        {\\n          token: $openAiApiKey,\\n          endpoint: $openAiEndpoint }) AS question_embedding\\n    CALL db.index.vector.queryNodes(\\n        \\'movie_tagline_embeddings\\',\\n        $top_k,\\n        question_embedding\\n        ) YIELD node AS movie, score\\n    RETURN movie.title, movie.tagline, score\\n    '\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.query(\"\"\"\n",
        "    WITH genai.vector.encode(\n",
        "        $question,\n",
        "        \"OpenAI\",\n",
        "        {\n",
        "          token: $openAiApiKey,\n",
        "          endpoint: $openAiEndpoint }) AS question_embedding\n",
        "    CALL db.index.vector.queryNodes(\n",
        "        'movie_tagline_embeddings',\n",
        "        $top_k,\n",
        "        question_embedding\n",
        "        ) YIELD node AS movie, score\n",
        "    RETURN movie.title, movie.tagline, score\n",
        "    \"\"\",\n",
        "    params={\"openAiApiKey\":OPENAI_API_KEY,\n",
        "            \"openAiEndpoint\": OPENAI_ENDPOINT,\n",
        "            \"question\": question,\n",
        "            \"top_k\": 5\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io9aI4_QCMUe",
        "outputId": "48ba4ba8-8ddd-4e47-e992-adf3ed6d01a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "factory                      366\n",
            "date                         366\n",
            "location                     366\n",
            "machine_type                 366\n",
            "machine_utilization_pcnt     366\n",
            "machine_downtime_hours       366\n",
            "maintenance_history          366\n",
            "machine_age_years            366\n",
            "batch_quality_pass_pcnt      366\n",
            "cycle_time_minutes           366\n",
            "energy_consumption_kwh       366\n",
            "energy_efficiency_rating     366\n",
            "co2_emissions_kg             366\n",
            "emission_limit_compliance    366\n",
            "waste_generated_kg           366\n",
            "water_usage_liters           366\n",
            "shift                        366\n",
            "operator_experience_years    366\n",
            "team_size                    366\n",
            "operator_training_level      366\n",
            "absenteeism_rate_pcnt        366\n",
            "product_category             366\n",
            "supplier                     366\n",
            "supplier_delays_days         366\n",
            "raw_material_quality         366\n",
            "market_demand_index          366\n",
            "cost_of_downtime_dolrs       366\n",
            "revenue_dolrs                366\n",
            "profit_margin_pcnt           366\n",
            "breakdowns_count             366\n",
            "safety_incidents_count       366\n",
            "defect_root_cause            294\n",
            "production_volume_units      366\n",
            "defect_rate_pcnt             366\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns                       #visualisation\n",
        "import matplotlib.pyplot as plt             #visualisation\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/Complex_Expanded_Factory_Data.csv\")\n",
        "\n",
        "\n",
        "from os import replace\n",
        "col_rename_lst = {}\n",
        "for series_name, series in df.items():\n",
        "  col_rename_lst[series_name] = series_name.replace(' ','_').replace('%','pcnt').replace('(','').replace(')','').replace('$','dolrs').lower()\n",
        "\n",
        "#print(col_rename_lst)\n",
        "\n",
        "df = df.rename(columns=col_rename_lst)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypElkLjkCMNG"
      },
      "outputs": [],
      "source": [
        "df_f = df[['factory','location']]\n",
        "df_f\n",
        "df_f.to_csv('factory.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uWIV3uxFPTh"
      },
      "outputs": [],
      "source": [
        "df_d = df[['date']]\n",
        "df_d['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_d.to_csv('date.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "10tKiFlUFweW"
      },
      "outputs": [],
      "source": [
        "df_m = df[['factory','location','date','machine_type','machine_utilization_pcnt','machine_downtime_hours','machine_age_years','cycle_time_minutes','energy_consumption_kwh','energy_efficiency_rating','co2_emissions_kg']]\n",
        "\n",
        "df_m['factory_machine']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_m.to_csv('machine.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qGzlzHwCIgcM"
      },
      "outputs": [],
      "source": [
        "df_pr = df[['batch_quality_pass_pcnt','waste_generated_kg','water_usage_liters','production_volume_units','defect_rate_pcnt','factory','date']]\n",
        "df_pr['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_pr.to_csv('production_run.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kRsvbMoZMu62"
      },
      "outputs": [],
      "source": [
        "df_s = df[['shift']]\n",
        "df_s['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_s.to_csv('shift.csv', index=False)\n",
        "\n",
        "df_o = df[['operator_experience_years','operator_training_level','factory','date']]\n",
        "df_o['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_o.to_csv('operator.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MO_tGGy1N4yl"
      },
      "outputs": [],
      "source": [
        "df_t = df[['team_size']]\n",
        "df_t['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_t.to_csv('team_size.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "HuJ-Nr6qOYhh"
      },
      "outputs": [],
      "source": [
        "df_p = df[['product_category']]\n",
        "df_p['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_p.to_csv('product_category.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k5khAztXPWOh"
      },
      "outputs": [],
      "source": [
        "df_sup = df[['supplier','supplier_delays_days','raw_material_quality']]\n",
        "df_sup['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_sup.to_csv('supplier.csv', index=False)\n",
        "\n",
        "\n",
        "df_mk = df[['market_demand_index']]\n",
        "df_mk['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_mk.to_csv('market_demand.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VLu3QjPvS7Lo"
      },
      "outputs": [],
      "source": [
        "df_d = df[['machine_downtime_hours']]\n",
        "df_d['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_d.to_csv('downtime.csv', index=False)\n",
        "\n",
        "df_si = df[['safety_incidents_count']]\n",
        "df_si['key_point']= df_m['factory']+'_'+df_m['location']+'_'+df_m['machine_type']+'_'+df_m['date']\n",
        "df_si.to_csv('safety_incidents.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmHcNrrWXrB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20-QLGgLVBob"
      },
      "outputs": [],
      "source": [
        "kg.query(\"\"\"LOAD CSV WITH HEADERS FROM \"/content/factory.csv\" AS row CREATE (f:Factory {name: \"Factory 1\", location: \"City D\"})\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
